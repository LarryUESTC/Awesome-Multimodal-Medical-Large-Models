# Awesome-Multimodal-Medical-Large-Models
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://makeapullrequest.com)

🔥  This is a collection of awesome (not comprehensive but high quality) papers about *Multimodal Medical Data Analysis*

✅ Continue update 2024.1.5

😊 If you have any recommended papers, pls feel free to contact me ([Email](larrypengliang@gmail.com) or WeChat: pl15828102252)

# Papers

1. 📜 **CLIP in medical imaging: A comprehensive survey**
    - 🗓️ Date: 2023.12
    - 📖 arXiv
    - 🧑‍ Authors: Zihao Zhao, Yuxiao Liu, Han Wu, Yonghao Li, Sheng Wang, Lin Teng, Disheng Liu, Zhiming Cui, Qian Wang, Dinggang Shen
    - 📄 [PDF](https://arxiv.org/pdf/2312.07353.pdf)
    - 💻 [GitHub](https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging)
    - 📌 Keys: CLIP, survey
    - 🔬 Datasets: survey

2. 📜 **CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization in Healthcare**
    - 🗓️ Date: 2023.12
    - 📖 AAAI 2024
    - 🧑‍ Authors: Akash Ghosh, Arkadeep Acharya, Raghav Jain, Sriparna Saha, Aman Chadha, Setu Sinha
    - 📄 [PDF](https://arxiv.org/pdf/2312.11541.pdf)
    - 💻 [GitHub](https://github.com/AkashGhosh/CLIPSyntel-AAAI2024)
    - 📌 Keys: CLIP, LLM, Question-summarization
    - 🔬 Datasets: MMQS

# Base papers

1. 📜 **CLIP**
    - 🗓️ Date: 2021.3
    - 📖 ICML 2021
    - 🧑‍ Authors: Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever
    - 📄 [PDF](https://arxiv.org/pdf/2103.00020.pdf)
    - 💻 [GitHub](https://github.com/openai/CLIP)
    - 📌 Keys: Contrastive Language-Image Pre-Training
    - 
2. 📜 **MaPLe: Multi-modal Prompt Learning**
    - 🗓️ Date: 2023
    - 📖 CVPR 2023
    - 🧑‍ Authors: Muhammad Uzair Khattak, Hanoona Rasheed, Muhammad Maaz, Salman Khan, Fahad Shahbaz Khan
    - 📄 [PDF](https://arxiv.org/pdf/2210.03117.pdf)
    - 💻 [GitHub](https://github.com/muzairkhattak/multimodal-prompt-learning)
    - 📌 Keys: Multi-modal Prompt, based on ClIP

3. 📜 **Meta-Transformer: A Unified Framework for Multimodal Learning**
    - 🗓️ Date: 2023
    - 📖 CVPR 2023
    - 🧑‍ Authors: Yiyuan Zhang, Kaixiong Gong, Kaipeng Zhang, Hongsheng Li, Yu Qiao, Wanli Ouyang, Xiangyu Yue
    - 📄 [PDF](https://arxiv.org/pdf/2307.10802.pdf)
    - 💻 [GitHub](https://github.com/invictus717/MetaTransformer)
    - 📌 Keys: Unified multi-modal Modal, token is all you need
   
# Datasets

| Name    | Modality | Size | Task | Organ | Link |
|---------|----------|------|------|-------|------|
| ADNI    |          |      |      |       |      |
|  ABIDE  |          |      |      |       |      |
| INSPECT |          |      |      |       |      |
|         |          |      |      |       |      |
|         |          |      |      |       |      |
|         |          |      |      |       |      |
|         |          |      |      |       |      |
|         |          |      |      |       |      |
|         |          |      |      |       |      |
